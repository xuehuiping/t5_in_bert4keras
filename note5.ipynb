{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xuehp/anaconda3/envs/t5_in_bert4keras/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/xuehp/anaconda3/envs/t5_in_bert4keras/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/xuehp/anaconda3/envs/t5_in_bert4keras/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/xuehp/anaconda3/envs/t5_in_bert4keras/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/xuehp/anaconda3/envs/t5_in_bert4keras/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/xuehp/anaconda3/envs/t5_in_bert4keras/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/xuehp/anaconda3/envs/t5_in_bert4keras/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/xuehp/anaconda3/envs/t5_in_bert4keras/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/xuehp/anaconda3/envs/t5_in_bert4keras/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/xuehp/anaconda3/envs/t5_in_bert4keras/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/xuehp/anaconda3/envs/t5_in_bert4keras/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/xuehp/anaconda3/envs/t5_in_bert4keras/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#! -*- coding: utf-8 -*-\n",
    "# 微调多国语言版T5做Seq2Seq任务\n",
    "# 介绍链接：kexue.fm/archives/7867\n",
    "# 数据集：https://github.com/CLUEbenchmark/CLGE 中的CSL数据集\n",
    "# 补充了评测指标bleu、rouge-1、rouge-2、rouge-l\n",
    "\n",
    "from __future__ import print_function\n",
    "import json\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from bert4keras.backend import keras, K\n",
    "from bert4keras.layers import Loss\n",
    "from bert4keras.models import build_transformer_model\n",
    "from bert4keras.tokenizers import SpTokenizer\n",
    "from bert4keras.optimizers import Adam\n",
    "from bert4keras.snippets import sequence_padding, open\n",
    "from bert4keras.snippets import DataGenerator, AutoRegressiveDecoder\n",
    "from keras.models import Model\n",
    "from rouge import Rouge  # pip install rouge\n",
    "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 基本参数\n",
    "max_c_len = 256\n",
    "max_t_len = 32\n",
    "batch_size = 16\n",
    "epochs = 40\n",
    "\n",
    "# 模型路径\n",
    "folder = './mt5/'\n",
    "config_path = folder + 'mt5_small_config.json'\n",
    "checkpoint_path = folder + 'mt5_small/model.ckpt-1000000'\n",
    "spm_path = folder + 'sentencepiece_cn.model'\n",
    "keep_tokens_path = folder + 'sentencepiece_cn_keep_tokens.json'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def load_data(filename):\n",
    "    D = []\n",
    "    with open(filename, encoding='utf-8') as f:\n",
    "        for l in f:\n",
    "            title, content = l.strip().split('\\t')\n",
    "            D.append((title, content))\n",
    "    return D\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 加载数据集\n",
    "data_folder = './csl_summary_dataset/'\n",
    "train_data = load_data(data_folder + 'train.tsv')\n",
    "valid_data = load_data(data_folder + 'val.tsv')\n",
    "test_data = load_data(data_folder + 'test.tsv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 加载分词器\n",
    "tokenizer = SpTokenizer(spm_path, token_start=None, token_end='</s>')\n",
    "keep_tokens = json.load(open(keep_tokens_path))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class data_generator(DataGenerator):\n",
    "    \"\"\"数据生成器\n",
    "    \"\"\"\n",
    "\n",
    "    def __iter__(self, random=False):\n",
    "        batch_c_token_ids, batch_t_token_ids = [], []\n",
    "        for is_end, (title, content) in self.sample(random):\n",
    "            c_token_ids, _ = tokenizer.encode(content, maxlen=max_c_len)\n",
    "            t_token_ids, _ = tokenizer.encode(title, maxlen=max_t_len)\n",
    "            batch_c_token_ids.append(c_token_ids)\n",
    "            batch_t_token_ids.append([0] + t_token_ids)\n",
    "            if len(batch_c_token_ids) == self.batch_size or is_end:\n",
    "                batch_c_token_ids = sequence_padding(batch_c_token_ids)\n",
    "                batch_t_token_ids = sequence_padding(batch_t_token_ids)\n",
    "                yield [batch_c_token_ids, batch_t_token_ids], None\n",
    "                batch_c_token_ids, batch_t_token_ids = [], []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class CrossEntropy(Loss):\n",
    "    \"\"\"交叉熵作为loss，并mask掉输入部分\n",
    "    \"\"\"\n",
    "\n",
    "    def compute_loss(self, inputs, mask=None):\n",
    "        y_true, y_pred = inputs\n",
    "        y_true = y_true[:, 1:]  # 目标token_ids\n",
    "        y_mask = K.cast(mask[1], K.floatx())[:, :-1]  # 解码器自带mask\n",
    "        y_pred = y_pred[:, :-1]  # 预测序列，错开一位\n",
    "        loss = K.sparse_categorical_crossentropy(y_true, y_pred)\n",
    "        loss = K.sum(loss * y_mask) / K.sum(y_mask)\n",
    "        return loss\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/xuehp/anaconda3/envs/t5_in_bert4keras/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3170: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "Encoder-Input-Token (InputLayer (None, None)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Embedding-Token (Embedding)     (None, None, 512)    16690176    Encoder-Input-Token[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-Embedding-Dropout (Drop (None, None, 512)    0           Embedding-Token[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-Transformer-0-MultiHead (None, None, 512)    512         Encoder-Embedding-Dropout[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-Embedding-Relative-Posi (None, None, 6)      192         Encoder-Embedding-Dropout[0][0]  \n",
      "                                                                 Encoder-Embedding-Dropout[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-Transformer-0-MultiHead (None, None, 512)    786432      Encoder-Transformer-0-MultiHeadSe\n",
      "                                                                 Encoder-Transformer-0-MultiHeadSe\n",
      "                                                                 Encoder-Transformer-0-MultiHeadSe\n",
      "                                                                 Encoder-Embedding-Relative-Positi\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-Transformer-0-MultiHead (None, None, 512)    0           Encoder-Transformer-0-MultiHeadSe\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-Transformer-0-MultiHead (None, None, 512)    0           Encoder-Embedding-Dropout[0][0]  \n",
      "                                                                 Encoder-Transformer-0-MultiHeadSe\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-Transformer-0-FeedForwa (None, None, 512)    512         Encoder-Transformer-0-MultiHeadSe\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-Transformer-0-FeedForwa (None, None, 512)    1572864     Encoder-Transformer-0-FeedForward\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-Transformer-0-FeedForwa (None, None, 512)    0           Encoder-Transformer-0-FeedForward\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-Transformer-0-FeedForwa (None, None, 512)    0           Encoder-Transformer-0-MultiHeadSe\n",
      "                                                                 Encoder-Transformer-0-FeedForward\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-Transformer-1-MultiHead (None, None, 512)    512         Encoder-Transformer-0-FeedForward\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-Transformer-1-MultiHead (None, None, 512)    786432      Encoder-Transformer-1-MultiHeadSe\n",
      "                                                                 Encoder-Transformer-1-MultiHeadSe\n",
      "                                                                 Encoder-Transformer-1-MultiHeadSe\n",
      "                                                                 Encoder-Embedding-Relative-Positi\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-Transformer-1-MultiHead (None, None, 512)    0           Encoder-Transformer-1-MultiHeadSe\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-Transformer-1-MultiHead (None, None, 512)    0           Encoder-Transformer-0-FeedForward\n",
      "                                                                 Encoder-Transformer-1-MultiHeadSe\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-Transformer-1-FeedForwa (None, None, 512)    512         Encoder-Transformer-1-MultiHeadSe\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-Transformer-1-FeedForwa (None, None, 512)    1572864     Encoder-Transformer-1-FeedForward\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-Transformer-1-FeedForwa (None, None, 512)    0           Encoder-Transformer-1-FeedForward\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-Transformer-1-FeedForwa (None, None, 512)    0           Encoder-Transformer-1-MultiHeadSe\n",
      "                                                                 Encoder-Transformer-1-FeedForward\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-Transformer-2-MultiHead (None, None, 512)    512         Encoder-Transformer-1-FeedForward\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-Transformer-2-MultiHead (None, None, 512)    786432      Encoder-Transformer-2-MultiHeadSe\n",
      "                                                                 Encoder-Transformer-2-MultiHeadSe\n",
      "                                                                 Encoder-Transformer-2-MultiHeadSe\n",
      "                                                                 Encoder-Embedding-Relative-Positi\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-Transformer-2-MultiHead (None, None, 512)    0           Encoder-Transformer-2-MultiHeadSe\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-Transformer-2-MultiHead (None, None, 512)    0           Encoder-Transformer-1-FeedForward\n",
      "                                                                 Encoder-Transformer-2-MultiHeadSe\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-Transformer-2-FeedForwa (None, None, 512)    512         Encoder-Transformer-2-MultiHeadSe\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-Transformer-2-FeedForwa (None, None, 512)    1572864     Encoder-Transformer-2-FeedForward\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-Transformer-2-FeedForwa (None, None, 512)    0           Encoder-Transformer-2-FeedForward\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-Transformer-2-FeedForwa (None, None, 512)    0           Encoder-Transformer-2-MultiHeadSe\n",
      "                                                                 Encoder-Transformer-2-FeedForward\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-Transformer-3-MultiHead (None, None, 512)    512         Encoder-Transformer-2-FeedForward\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-Transformer-3-MultiHead (None, None, 512)    786432      Encoder-Transformer-3-MultiHeadSe\n",
      "                                                                 Encoder-Transformer-3-MultiHeadSe\n",
      "                                                                 Encoder-Transformer-3-MultiHeadSe\n",
      "                                                                 Encoder-Embedding-Relative-Positi\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-Transformer-3-MultiHead (None, None, 512)    0           Encoder-Transformer-3-MultiHeadSe\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-Transformer-3-MultiHead (None, None, 512)    0           Encoder-Transformer-2-FeedForward\n",
      "                                                                 Encoder-Transformer-3-MultiHeadSe\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-Transformer-3-FeedForwa (None, None, 512)    512         Encoder-Transformer-3-MultiHeadSe\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-Transformer-3-FeedForwa (None, None, 512)    1572864     Encoder-Transformer-3-FeedForward\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-Transformer-3-FeedForwa (None, None, 512)    0           Encoder-Transformer-3-FeedForward\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-Transformer-3-FeedForwa (None, None, 512)    0           Encoder-Transformer-3-MultiHeadSe\n",
      "                                                                 Encoder-Transformer-3-FeedForward\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-Transformer-4-MultiHead (None, None, 512)    512         Encoder-Transformer-3-FeedForward\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-Transformer-4-MultiHead (None, None, 512)    786432      Encoder-Transformer-4-MultiHeadSe\n",
      "                                                                 Encoder-Transformer-4-MultiHeadSe\n",
      "                                                                 Encoder-Transformer-4-MultiHeadSe\n",
      "                                                                 Encoder-Embedding-Relative-Positi\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-Transformer-4-MultiHead (None, None, 512)    0           Encoder-Transformer-4-MultiHeadSe\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-Transformer-4-MultiHead (None, None, 512)    0           Encoder-Transformer-3-FeedForward\n",
      "                                                                 Encoder-Transformer-4-MultiHeadSe\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-Transformer-4-FeedForwa (None, None, 512)    512         Encoder-Transformer-4-MultiHeadSe\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-Transformer-4-FeedForwa (None, None, 512)    1572864     Encoder-Transformer-4-FeedForward\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-Transformer-4-FeedForwa (None, None, 512)    0           Encoder-Transformer-4-FeedForward\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-Transformer-4-FeedForwa (None, None, 512)    0           Encoder-Transformer-4-MultiHeadSe\n",
      "                                                                 Encoder-Transformer-4-FeedForward\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-Transformer-5-MultiHead (None, None, 512)    512         Encoder-Transformer-4-FeedForward\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-Transformer-5-MultiHead (None, None, 512)    786432      Encoder-Transformer-5-MultiHeadSe\n",
      "                                                                 Encoder-Transformer-5-MultiHeadSe\n",
      "                                                                 Encoder-Transformer-5-MultiHeadSe\n",
      "                                                                 Encoder-Embedding-Relative-Positi\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-Transformer-5-MultiHead (None, None, 512)    0           Encoder-Transformer-5-MultiHeadSe\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-Transformer-5-MultiHead (None, None, 512)    0           Encoder-Transformer-4-FeedForward\n",
      "                                                                 Encoder-Transformer-5-MultiHeadSe\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-Transformer-5-FeedForwa (None, None, 512)    512         Encoder-Transformer-5-MultiHeadSe\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-Transformer-5-FeedForwa (None, None, 512)    1572864     Encoder-Transformer-5-FeedForward\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-Transformer-5-FeedForwa (None, None, 512)    0           Encoder-Transformer-5-FeedForward\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-Transformer-5-FeedForwa (None, None, 512)    0           Encoder-Transformer-5-MultiHeadSe\n",
      "                                                                 Encoder-Transformer-5-FeedForward\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-Transformer-6-MultiHead (None, None, 512)    512         Encoder-Transformer-5-FeedForward\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-Transformer-6-MultiHead (None, None, 512)    786432      Encoder-Transformer-6-MultiHeadSe\n",
      "                                                                 Encoder-Transformer-6-MultiHeadSe\n",
      "                                                                 Encoder-Transformer-6-MultiHeadSe\n",
      "                                                                 Encoder-Embedding-Relative-Positi\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-Transformer-6-MultiHead (None, None, 512)    0           Encoder-Transformer-6-MultiHeadSe\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-Transformer-6-MultiHead (None, None, 512)    0           Encoder-Transformer-5-FeedForward\n",
      "                                                                 Encoder-Transformer-6-MultiHeadSe\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-Transformer-6-FeedForwa (None, None, 512)    512         Encoder-Transformer-6-MultiHeadSe\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-Transformer-6-FeedForwa (None, None, 512)    1572864     Encoder-Transformer-6-FeedForward\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-Transformer-6-FeedForwa (None, None, 512)    0           Encoder-Transformer-6-FeedForward\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-Transformer-6-FeedForwa (None, None, 512)    0           Encoder-Transformer-6-MultiHeadSe\n",
      "                                                                 Encoder-Transformer-6-FeedForward\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-Transformer-7-MultiHead (None, None, 512)    512         Encoder-Transformer-6-FeedForward\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-Transformer-7-MultiHead (None, None, 512)    786432      Encoder-Transformer-7-MultiHeadSe\n",
      "                                                                 Encoder-Transformer-7-MultiHeadSe\n",
      "                                                                 Encoder-Transformer-7-MultiHeadSe\n",
      "                                                                 Encoder-Embedding-Relative-Positi\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-Transformer-7-MultiHead (None, None, 512)    0           Encoder-Transformer-7-MultiHeadSe\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-Transformer-7-MultiHead (None, None, 512)    0           Encoder-Transformer-6-FeedForward\n",
      "                                                                 Encoder-Transformer-7-MultiHeadSe\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-Transformer-7-FeedForwa (None, None, 512)    512         Encoder-Transformer-7-MultiHeadSe\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-Transformer-7-FeedForwa (None, None, 512)    1572864     Encoder-Transformer-7-FeedForward\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-Transformer-7-FeedForwa (None, None, 512)    0           Encoder-Transformer-7-FeedForward\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-Transformer-7-FeedForwa (None, None, 512)    0           Encoder-Transformer-7-MultiHeadSe\n",
      "                                                                 Encoder-Transformer-7-FeedForward\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-Output-Norm (LayerNorma (None, None, 512)    512         Encoder-Transformer-7-FeedForward\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-Output-Dropout (Dropout (None, None, 512)    0           Encoder-Output-Norm[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Decoder-Input-Token (InputLayer (None, None)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "T5_Decoder (Model)              (None, None, 32598)  58559168    Encoder-Output-Dropout[0][0]     \n",
      "                                                                 Decoder-Input-Token[0][0]        \n",
      "==================================================================================================\n",
      "Total params: 77,442,432\n",
      "Trainable params: 77,442,432\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "t5 = build_transformer_model(\n",
    "    config_path=config_path,\n",
    "    checkpoint_path=checkpoint_path,\n",
    "    keep_tokens=keep_tokens,\n",
    "    model='t5.1.1',\n",
    "    return_keras_model=False,\n",
    "    name='T5',\n",
    ")\n",
    "\n",
    "encoder = t5.encoder\n",
    "decoder = t5.decoder\n",
    "model = t5.model\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xuehp/anaconda3/envs/t5_in_bert4keras/lib/python3.6/site-packages/keras/engine/training_utils.py:819: UserWarning: Output cross_entropy_1 missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to cross_entropy_1.\n",
      "  'be expecting any data to be passed to {0}.'.format(name))\n"
     ]
    }
   ],
   "source": [
    "\n",
    "output = CrossEntropy(1)([model.inputs[1], model.outputs[0]])\n",
    "\n",
    "model = Model(model.inputs, output)\n",
    "model.compile(optimizer=Adam(2e-4))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class AutoTitle(AutoRegressiveDecoder):\n",
    "    \"\"\"seq2seq解码器\n",
    "    \"\"\"\n",
    "\n",
    "    @AutoRegressiveDecoder.wraps(default_rtype='probas')\n",
    "    def predict(self, inputs, output_ids, states):\n",
    "        c_encoded = inputs[0]\n",
    "        return decoder.predict([c_encoded, output_ids])[:, -1]\n",
    "\n",
    "    def generate(self, text, topk=1):\n",
    "        c_token_ids, _ = tokenizer.encode(text, maxlen=max_c_len)\n",
    "        c_encoded = encoder.predict(np.array([c_token_ids]))[0]\n",
    "        output_ids = self.beam_search([c_encoded], topk)  # 基于beam search\n",
    "        return tokenizer.decode([int(i) for i in output_ids])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 注：T5有一个很让人不解的设置，它的<bos>标记id是0，即<bos>和<pad>其实都是0\n",
    "autotitle = AutoTitle(start_id=0, end_id=tokenizer._token_end_id, maxlen=32)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Evaluator(keras.callbacks.Callback):\n",
    "    \"\"\"评估与保存\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.rouge = Rouge()\n",
    "        self.smooth = SmoothingFunction().method1\n",
    "        self.best_bleu = 0.\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        metrics = self.evaluate(valid_data)  # 评测模型\n",
    "        if metrics['bleu'] > self.best_bleu:\n",
    "            self.best_bleu = metrics['bleu']\n",
    "            model.save_weights('./best_model.weights')  # 保存模型\n",
    "        metrics['best_bleu'] = self.best_bleu\n",
    "        print('valid_data:', metrics)\n",
    "\n",
    "    def evaluate(self, data, topk=1):\n",
    "        total = 0\n",
    "        rouge_1, rouge_2, rouge_l, bleu = 0, 0, 0, 0\n",
    "        for title, content in tqdm(data):\n",
    "            total += 1\n",
    "            title = ' '.join(title).lower()\n",
    "            pred_title = ' '.join(autotitle.generate(content, topk)).lower()\n",
    "            if pred_title.strip():\n",
    "                scores = self.rouge.get_scores(hyps=pred_title, refs=title)\n",
    "                rouge_1 += scores[0]['rouge-1']['f']\n",
    "                rouge_2 += scores[0]['rouge-2']['f']\n",
    "                rouge_l += scores[0]['rouge-l']['f']\n",
    "                bleu += sentence_bleu(\n",
    "                    references=[title.split(' ')],\n",
    "                    hypothesis=pred_title.split(' '),\n",
    "                    smoothing_function=self.smooth\n",
    "                )\n",
    "        rouge_1 /= total\n",
    "        rouge_2 /= total\n",
    "        rouge_l /= total\n",
    "        bleu /= total\n",
    "        return {\n",
    "            'rouge-1': rouge_1,\n",
    "            'rouge-2': rouge_2,\n",
    "            'rouge-l': rouge_l,\n",
    "            'bleu': bleu,\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/1000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/xuehp/anaconda3/envs/t5_in_bert4keras/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [06:58<00:00,  2.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'rouge-1': 0.6745963715335307, 'rouge-2': 0.5690859850235804, 'rouge-l': 0.6541478671387893, 'bleu': 0.478420268425949}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# 加载模型，评测验证集\n",
    "\n",
    "model.load_weights('./best_model.weights')\n",
    "\n",
    "evaluator = Evaluator()\n",
    "metrics = evaluator.evaluate(valid_data)  # 评测模型\n",
    "print(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
